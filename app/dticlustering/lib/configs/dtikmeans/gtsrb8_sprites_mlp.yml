dataset:
  name: gtsrb8
model:
  name: dtikmeans
  n_sprites: 8
  prototype:
    source: generator
    generator: mlp
    data:
  encoder_name: resnet32
  transformation_sequence: color_projective_tps
  transformation_sequence_bkg: color_projective_tps
  curriculum_learning: [100, 350]
  curriculum_learning_bkg: [100, 350]
training:
  batch_size: 128
  n_workers: 4
  optimizer:
    name: adam
    lr: 1.0e-3
    transformer:
      weight_decay: 1.0e-6
  scheduler:
    name: multi_step
    gamma: 0.1
    milestones: [600]
  n_epoches: 700
  train_stat_interval: 100
  val_stat_interval: 200
  check_cluster_interval: 25
  seed: 4820
  visualizer_port:
  pretrained: 
  resume: 
