dataset:
  name: Lettre_e
  img_size: [32, 32]
model:
  name: dti_sprites
  n_sprites: 10
  n_backgrounds: 1
  n_objects: 1
  prototype:
    source: generator
    generator: mlp
    data:
      freeze: [1, 0, 500]
      value: [0.1, 0.9, 0.]
      init: ["constant", "constant", "gaussian"] 
      gaussian_weights_std: 25
  encoder_name: resnet32
  transformation_sequence: identity_color_affine
  transformation_sequence_bkg: color
  curriculum_learning: [500, 500]
  curriculum_learning_bkg: False 
  shared_t: True
training:
  batch_size: 32
  n_workers: 4
  optimizer:
    name: adam
    lr: 1.0e-3
    transformer:
      weight_decay: 1.0e-6
  scheduler:
    name: multi_step
    gamma: 0.1
    milestones: [1300]
  n_epoches: 1600
  train_stat_interval: 200
  val_stat_interval: 100
  check_cluster_interval: 100
  seed: 24169
  n_dup: 0
  visualizer_port:
